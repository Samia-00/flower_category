{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"customized added conv2d.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GaMgUNzWBVPx","executionInfo":{"status":"ok","timestamp":1620991883415,"user_tz":0,"elapsed":945,"user":{"displayName":"Rasel Khondokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOUSO9zTFKLFHK2XbIsUh63TTHQOt3MNVisj-c=s64","userId":"03678518181698765278"}},"outputId":"7f9f3726-8fea-4afa-f9e5-205638fbb90f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BLTR8MD3klJg"},"source":["import datetime\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import shutil\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","import math\n","import tensorflow as tf\n","from IPython.display import Image, display\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import Input\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from keras.optimizers import SGD\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDNbjCraksN3","executionInfo":{"status":"ok","timestamp":1620991889905,"user_tz":0,"elapsed":7429,"user":{"displayName":"Rasel Khondokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOUSO9zTFKLFHK2XbIsUh63TTHQOt3MNVisj-c=s64","userId":"03678518181698765278"}},"outputId":"28f6b778-3947-45fc-fa39-1092124dc39b"},"source":["train_folder = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/train'\n","labels = os.listdir(train_folder)\n","num_classes = len(set(labels))\n","image_size = 224\n","batch_size=24\n","train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                    horizontal_flip=True,\n","                                    width_shift_range=0.2,\n","                                    height_shift_range=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1190 images belonging to 17 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PcOXBN99jmC","executionInfo":{"status":"ok","timestamp":1620991889905,"user_tz":0,"elapsed":7426,"user":{"displayName":"Rasel Khondokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOUSO9zTFKLFHK2XbIsUh63TTHQOt3MNVisj-c=s64","userId":"03678518181698765278"}},"outputId":"d222468e-2f28-4231-adfa-a58b0ec80297"},"source":["train_folder = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/train'\n","data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                    horizontal_flip=True,\n","                                    width_shift_range=0.2,\n","                                    height_shift_range=0.2,\n","                                    validation_split=0.2)# set validation split\n","\n","train_generator = data_generator.flow_from_directory(\n","    train_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical',\n","    subset='training'\n","    )\n","validation_generator = data_generator.flow_from_directory(\n","    train_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical',\n","    subset='validation'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 952 images belonging to 17 classes.\n","Found 238 images belonging to 17 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HVW5E6a4j51","executionInfo":{"status":"ok","timestamp":1620991891545,"user_tz":0,"elapsed":9063,"user":{"displayName":"Rasel Khondokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOUSO9zTFKLFHK2XbIsUh63TTHQOt3MNVisj-c=s64","userId":"03678518181698765278"}},"outputId":"06d5db8c-c8d7-4a0d-b9c5-55f60f3889c8"},"source":["test_folder = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/test'\n","test_generator = data_generator.flow_from_directory(\n","    test_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 170 images belonging to 17 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-KlkSYsSHNr","executionInfo":{"status":"ok","timestamp":1620991891545,"user_tz":0,"elapsed":9060,"user":{"displayName":"Rasel Khondokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOUSO9zTFKLFHK2XbIsUh63TTHQOt3MNVisj-c=s64","userId":"03678518181698765278"}},"outputId":"d940f75d-ff65-4700-98fe-df0a8565ad5b"},"source":["test_generator.image_shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZJJ0K-Olaqk","executionInfo":{"status":"ok","timestamp":1620992378926,"user_tz":0,"elapsed":3619,"user":{"displayName":"Rasel Khondokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOUSO9zTFKLFHK2XbIsUh63TTHQOt3MNVisj-c=s64","userId":"03678518181698765278"}},"outputId":"983f546a-114d-486c-e606-af2231551c82"},"source":["# Create model\n","model = Sequential()\n","base_model =  ResNet50(weights=\"imagenet\", include_top=False,\n","\tinput_tensor=Input(shape=(image_size, image_size, 3)))\n","\n","model.add(base_model)\n","model.add(Conv2D(256, (3, 3), activation=\"relu\", padding='same'))\n","# model.add(AveragePooling2D(pool_size=(7, 7), padding='same'))\n","\n","model.add(Conv2D(256, (3, 3), activation=\"relu\", padding='same'))\n","# model.add(AveragePooling2D(pool_size=(7, 7), padding='same'))\n","\n","model.add(Conv2D(256, (3, 3), activation=\"relu\", padding='same'))\n","# model.add(AveragePooling2D(pool_size=(3, 3), padding='same'))\n","\n","model.add(Flatten())\n","# model.add(Dense(256, activation='relu'))\n","# model.add(Dropout(.5))\n","# model.add(BatchNormalization())\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","# Do not train first layer (ResNet) as it is already pre-trained\n","base_model.trainable = True\n","\n","# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Fine-tune from this layer onwards\n","fine_tune_at = 100\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable =  False\n","\n","# Compile model\n","sgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","print()\n","print(\"Number of layers in trainable: \", len(model.trainable_variables))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of layers in the base model:  175\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 7, 7, 256)         4718848   \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 7, 7, 256)         590080    \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 7, 7, 256)         590080    \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 12544)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 17)                213265    \n","=================================================================\n","Total params: 29,699,985\n","Trainable params: 25,565,201\n","Non-trainable params: 4,134,784\n","_________________________________________________________________\n","\n","Number of layers in trainable:  98\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3D3hrQNnQ5i","executionInfo":{"status":"ok","timestamp":1620993264953,"user_tz":0,"elapsed":880474,"user":{"displayName":"Rasel Khondokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOUSO9zTFKLFHK2XbIsUh63TTHQOt3MNVisj-c=s64","userId":"03678518181698765278"}},"outputId":"23dfd513-f099-4440-8e99-6ab50e5eebc5"},"source":["NUM_EPOCHS = 100\n","EARLY_STOP_PATIENCE = 5\n","# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n","\n","\n","cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n","cb_checkpointer = ModelCheckpoint(filepath = '/content/gdrive/MyDrive/Projects/flower_category_prediction/customized_best.hdf5',\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'auto')\n","start = datetime.datetime.now()\n","fit_history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=10,\n","    validation_data=validation_generator,\n","    validation_steps=10,\n","    epochs=NUM_EPOCHS,\n","    callbacks=[cb_checkpointer, cb_early_stopper])\n","\n","end = datetime.datetime.now()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","10/10 [==============================] - 151s 15s/step - loss: 4.6896 - accuracy: 0.0636 - val_loss: 2.8549 - val_accuracy: 0.1345\n","Epoch 2/100\n","10/10 [==============================] - 144s 15s/step - loss: 2.6399 - accuracy: 0.1155 - val_loss: 5.2971 - val_accuracy: 0.1681\n","Epoch 3/100\n","10/10 [==============================] - 145s 15s/step - loss: 2.2594 - accuracy: 0.2782 - val_loss: 29.8767 - val_accuracy: 0.1429\n","Epoch 4/100\n","10/10 [==============================] - 149s 15s/step - loss: 1.6402 - accuracy: 0.4781 - val_loss: 29.4699 - val_accuracy: 0.0714\n","Epoch 5/100\n","10/10 [==============================] - 143s 15s/step - loss: 1.4272 - accuracy: 0.5290 - val_loss: 62.3072 - val_accuracy: 0.0588\n","Epoch 6/100\n","10/10 [==============================] - 143s 15s/step - loss: 1.3242 - accuracy: 0.5146 - val_loss: 124.2596 - val_accuracy: 0.0588\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q0bTL0gHcxUL"},"source":["print('Execution time : ', end-start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2WwTbz8i44m"},"source":["model.load_weights(\"/content/gdrive/MyDrive/Projects/flower_category_prediction/customized_best.hdf5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIEk8fq3qSLj"},"source":["plt.figure(1, figsize = (15,8)) \n","plt.subplot(221)  \n","plt.plot(fit_history.history['accuracy'])  \n","plt.plot(fit_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'valid']) \n","plt.subplot(222)  \n","plt.plot(fit_history.history['loss'])  \n","plt.plot(fit_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'valid']) \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rrMpB7c-w9P"},"source":["train_steps = train_generator.n // batch_size\n","val_steps = validation_generator.n // batch_size\n","test_steps = test_generator.n // batch_size\n","# evaluate performance on train, val & test datasets\n","loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1, workers=3)\n","print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n","loss, acc = model.evaluate_generator(validation_generator, steps=val_steps, verbose=1, workers=3)\n","print('Validation data -> loss: %.3f, acc: %.3f' % (loss, acc))\n","loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1, workers=3)\n","print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4FpMFsam0c0v"},"source":["def predict_category(img_file):\n","    img = load_img(img_file, target_size=(image_size, image_size))\n","    x = img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    classes = model.predict_classes(x)\n","    return classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0wqhI-50_nh"},"source":["import os\n","classes_dict = train_generator.class_indices\n","test_img_path = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/test'\n","test_img_dirs = os.listdir(test_img_path)\n","\n","x_test, y_test, y_pred, test_img_paths = [], [], [], []\n","for dir in test_img_dirs:\n","    img_file_names = os.listdir(f'{test_img_path}/{dir}')\n","    for img_file in img_file_names:\n","        test_img_paths.append(f'{dir}/{img_file}')\n","        img_path = f'{test_img_path}/{dir}/{img_file}'\n","        # print(img_path)\n","        x_test.append(load_img(img_path))\n","        category = predict_category(img_path)\n","        # print(category)\n","        pred = list(classes_dict.keys())[list(classes_dict.values()).index(category[0])]\n","        y_pred.append(pred)\n","        y_test.append(dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGWmV8tN9nsE"},"source":["def plot_wrong_predictions(x_test, y_test, y_pred, test_img_paths, n = 1):\n","    count = 0\n","    for input, prediction, actual, test_img_path in zip (x_test, y_pred, y_test, test_img_paths):\n","        if count < n:\n","            if prediction != actual:\n","                print(test_img_path)\n","                print(f'Actual : {actual}, Predicted : {prediction}')\n","                plt.imshow(input)\n","                plt.show()\n","                count+=1\n","plot_wrong_predictions(x_test, y_test, y_pred, test_img_paths, n = 3)"],"execution_count":null,"outputs":[]}]}