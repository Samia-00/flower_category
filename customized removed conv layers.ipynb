{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"customized removed conv layers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"GaMgUNzWBVPx"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLTR8MD3klJg"},"source":["import datetime\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import shutil\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","import math\n","import tensorflow as tf\n","from IPython.display import Image, display\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import Input\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from keras.optimizers import SGD\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDNbjCraksN3"},"source":["train_folder = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/train'\n","labels = os.listdir(train_folder)\n","num_classes = len(set(labels))\n","image_size = 224\n","batch_size=24\n","train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                    horizontal_flip=True,\n","                                    width_shift_range=0.2,\n","                                    height_shift_range=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical'\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PcOXBN99jmC"},"source":["train_folder = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/train'\n","data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                    horizontal_flip=True,\n","                                    width_shift_range=0.2,\n","                                    height_shift_range=0.2,\n","                                    validation_split=0.2)# set validation split\n","\n","train_generator = data_generator.flow_from_directory(\n","    train_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical',\n","    subset='training'\n","    )\n","validation_generator = data_generator.flow_from_directory(\n","    train_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical',\n","    subset='validation'\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HVW5E6a4j51"},"source":["test_folder = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/test'\n","test_generator = data_generator.flow_from_directory(\n","    test_folder,\n","    target_size=(image_size, image_size),\n","    batch_size=24,\n","    class_mode='categorical'\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-KlkSYsSHNr"},"source":["test_generator.image_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZJJ0K-Olaqk"},"source":["# Create model\n","# model = Sequential()\n","base_model = ResNet50(include_top=False, pooling='avg', weights='imagenet')\n","base_model.summary()\n","print(\"Number of layers in trainable: \", len(base_model.trainable_variables))\n","# base_input = base_model.layers[0].input\n","# base_output = base_model.layers[-2].output\n","# final_output = Dense(num_classes, activation='softmax')(base_output)\n","# customized_model = Model(inputs = base_input, outputs = final_output)\n","\n","\n","# model.add(base_model)\n","# model.add(Dense(256, activation='relu'))\n","# model.add(Dropout(.5))\n","# model.add(BatchNormalization())\n","# model.add(Dense(num_classes, activation='softmax'))\n","\n","# Do not train first layer (ResNet) as it is already pre-trained\n","# base_model.trainable = True\n","\n","# # Let's take a look to see how many layers are in the base model\n","# print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Fine-tune from this layer onwards\n","# fine_tune_at = 150\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","# for layer in base_model.layers[:fine_tune_at]:\n","#   layer.trainable =  False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_BBsOp5NS_OF"},"source":["base_input = base_model.layers[0].input\n","base_output = base_model.layers[-12].output\n","avg = GlobalAveragePooling2D()(base_output)\n","final_output = Dense(num_classes, activation='softmax')(avg)\n","model = Model(inputs = base_input, outputs = final_output)\n","model.summary()\n","print(\"Number of layers in trainable: \", len(model.trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZ-whYBiXZDA"},"source":["# Compile model\n","sgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","print(\"Number of layers in trainable: \", len(model.trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3D3hrQNnQ5i"},"source":["NUM_EPOCHS = 100\n","EARLY_STOP_PATIENCE = 5\n","# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n","\n","\n","cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n","cb_checkpointer = ModelCheckpoint(filepath = '/content/gdrive/MyDrive/Projects/flower_category_prediction/customized_best.hdf5',\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'auto')\n","start = datetime.datetime.now()\n","fit_history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=10,\n","    validation_data=validation_generator,\n","    validation_steps=10,\n","    epochs=NUM_EPOCHS,\n","    callbacks=[cb_checkpointer, cb_early_stopper])\n","\n","end = datetime.datetime.now()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q0bTL0gHcxUL"},"source":["print('Execution time : ', end-start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2WwTbz8i44m"},"source":["model.load_weights(\"/content/gdrive/MyDrive/Projects/flower_category_prediction/customized_best.hdf5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIEk8fq3qSLj"},"source":["plt.figure(1, figsize = (15,8)) \n","plt.subplot(221)  \n","plt.plot(fit_history.history['accuracy'])  \n","plt.plot(fit_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'valid']) \n","plt.subplot(222)  \n","plt.plot(fit_history.history['loss'])  \n","plt.plot(fit_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'valid']) \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rrMpB7c-w9P"},"source":["train_steps = train_generator.n // batch_size\n","val_steps = validation_generator.n // batch_size\n","test_steps = test_generator.n // batch_size\n","# evaluate performance on train, val & test datasets\n","loss, acc = model.evaluate_generator(train_generator, steps=train_steps, verbose=1, workers=3)\n","print('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\n","loss, acc = model.evaluate_generator(validation_generator, steps=val_steps, verbose=1, workers=3)\n","print('Validation data -> loss: %.3f, acc: %.3f' % (loss, acc))\n","loss, acc = model.evaluate_generator(test_generator, steps=test_steps, verbose=1, workers=3)\n","print('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4FpMFsam0c0v"},"source":["def predict_category(img_file):\n","    img = load_img(img_file, target_size=(image_size, image_size))\n","    x = img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    # classes = model.predict_classes(x)\n","    y_proba=model.predict(x)\n","    return y_proba.argmax()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0wqhI-50_nh"},"source":["import os\n","classes_dict = train_generator.class_indices\n","test_img_path = '/content/gdrive/MyDrive/Projects/flower_category_prediction/flower_dataset/test'\n","test_img_dirs = os.listdir(test_img_path)\n","\n","x_test, y_test, y_pred, test_img_paths = [], [], [], []\n","for dir in test_img_dirs:\n","    img_file_names = os.listdir(f'{test_img_path}/{dir}')\n","    for img_file in img_file_names:\n","        test_img_paths.append(f'{dir}/{img_file}')\n","        img_path = f'{test_img_path}/{dir}/{img_file}'\n","        # print(img_path)\n","        x_test.append(load_img(img_path))\n","        category = predict_category(img_path)\n","        # print(category)\n","        pred = list(classes_dict.keys())[list(classes_dict.values()).index(category)]\n","        y_pred.append(pred)\n","        y_test.append(dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGWmV8tN9nsE"},"source":["def plot_wrong_predictions(x_test, y_test, y_pred, test_img_paths, n = 1):\n","    count = 0\n","    for input, prediction, actual, test_img_path in zip (x_test, y_pred, y_test, test_img_paths):\n","        if count < n:\n","            if prediction != actual:\n","                print(test_img_path)\n","                print(f'Actual : {actual}, Predicted : {prediction}')\n","                plt.imshow(input)\n","                plt.show()\n","                count+=1\n","plot_wrong_predictions(x_test, y_test, y_pred, test_img_paths, n = 3)"],"execution_count":null,"outputs":[]}]}